{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77683888",
   "metadata": {},
   "source": [
    "# SmolVLM2-Image\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "### Reference:\n",
    "- ***Paper***\n",
    "    - ...\n",
    "- ***Blogs***\n",
    "    - [SmolVLM2: Bringing Video Understanding to Every Device](https://huggingface.co/blog/smolvlm2)\n",
    "    - https://huggingface.co/HuggingFaceTB/SmolVLM-256M-Instruct\n",
    "    - [SmolVLM to SmolVLM2: Compact Models for Multi-Image VQA](https://pyimagesearch.com/2025/06/23/smolvlm-to-smolvlm2-compact-models-for-multi-image-vqa/)\n",
    "- ***GitHub***\n",
    "    - ...\n",
    "\n",
    "----\n",
    "\n",
    "### Conda env : [cv_playgrounds](../README.md#setup-a-conda-environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b09f7cf",
   "metadata": {},
   "source": [
    "## Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc598956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 18 10:54:08 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 27%   46C    P5             38W /  250W |    1322MiB /  11264MiB |     36%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2105      G   /usr/lib/xorg/Xorg                      652MiB |\n",
      "|    0   N/A  N/A            2285      G   /usr/bin/gnome-shell                    110MiB |\n",
      "|    0   N/A  N/A            4554      G   ...ersion=20250917-050038.719000         89MiB |\n",
      "|    0   N/A  N/A            6126      G   /usr/share/code/code                    408MiB |\n",
      "|    0   N/A  N/A           21502      G   ...ess --variations-seed-version         22MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Available device : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    g_device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    g_device = \"cuda\"\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    g_device = \"cpu\"\n",
    "\n",
    "print(f\"Available device : {g_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ba021",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e331b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890967dd9d4a48bcb1f70df302ece148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "\n",
    "model_path = \"HuggingFaceTB/SmolVLM-256M-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # _attn_implementation=\"flash_attention_2\"\n",
    ").to(g_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61760ba",
   "metadata": {},
   "source": [
    "##  Image Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee058c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "\n",
      "\n",
      "Can you describe this image?\n",
      "Assistant: The image depicts a close-up view of a flower with a distinctively colored blossom. The flower is prominently featured in the foreground, with its petals fully open and a central yellow center. The petals are a deep shade of pink, and the edges are slightly curled, giving the flower a delicate and delicate appearance.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe this image?\"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "display(Image(url='https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg', width=500))\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=64)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "print(generated_texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea0a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "\n",
      "\n",
      "Can you describe this image?\n",
      "Assistant: The image depicts a large, historic statue of Liberty situated on a small island in a body of water. The statue is a green, cylindrical structure with a human figure at the top, which is the actual statue of Liberty. The statue is mounted on a pedestal that is supported by a cylindrical base. The base of the pedestal is made of stone and has a rounded top, which is typical of pedestal bases used for statues.\n",
      "\n",
      "The statue is surrounded by a large body of water, which is likely the Hudson River, as indicated by the presence of trees and a small dock extending from the water's edge. The water is calm, with gentle ripples indicating the gentle movement of the water.\n",
      "\n",
      "In the background, there are several tall buildings, including a modern skyscraper and a more traditional building, which are both part of the cityscape. The buildings are constructed with glass and steel, and they are of varying heights, with some taller structures closer to the waterfront and others closer to the skyline. The sky is clear, with a few clouds visible, indicating fair weather.\n",
      "\n",
      "The overall scene suggests a peaceful and historic location, likely a tourist attraction or a public park. The statue is likely a representation of liberty, as it is a central symbol of the city and the United States.\n",
      "\n",
      "To summarize:\n",
      "- The statue is located on a small island in a body of water.\n",
      "- The statue is green and cylindrical, with a human figure at the top.\n",
      "- The pedestal is made of stone and has a rounded top.\n",
      "- The water is calm with gentle ripples.\n",
      "- The background includes tall buildings, including a modern skyscraper and a historic building.\n",
      "- The sky is clear with a few clouds.\n",
      "\n",
      "This detailed description provides a comprehensive understanding of the image, allowing a text-based model to answer any questions related to the image.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from transformers.image_utils import load_image\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Load images\n",
    "image = load_image(\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\")\n",
    "display(Image(url='https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg', width=500))\n",
    "# Create input messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe this image?\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "inputs = inputs.to(g_device)\n",
    "\n",
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "print(generated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab72152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\" width=\"400\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg\" width=\"300\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the differences between these two images?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Assistant: A rabbit in a blue coat stands in a dirt path with a village in the background.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "image1_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"\n",
    "display(Image(url=image1_url, width=400, height=300))\n",
    "\n",
    "image2_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg\"\n",
    "display(Image(url=image2_url, width=300, height=400))\n",
    "\n",
    "messages = [\n",
    "   {\n",
    "       \"role\": \"user\",\n",
    "       \"content\": [\n",
    "           {\"type\": \"text\", \"text\": \"What are the differences between these two images?\"},\n",
    "         {\"type\": \"image\", \"url\": image1_url},\n",
    "         {\"type\": \"image\", \"url\": image2_url},\n",
    "       ]\n",
    "   },\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "   messages,\n",
    "   add_generation_prompt=True,\n",
    "   tokenize=True,\n",
    "   return_dict=True,\n",
    "   return_tensors=\"pt\",\n",
    ").to(g_device, dtype=torch.bfloat16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=100)\n",
    "generated_texts = processor.batch_decode(\n",
    "   generated_ids,\n",
    "   skip_special_tokens=True,\n",
    ")\n",
    "print(generated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7ebb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./data/test01.mp4\" controls  width=\"640\"  height=\"360\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "# video_url = \"https://huggingface.co/datasets/nateraw/kinetics-mini/resolve/main/val/bowling/-WH-lxmGJVY_000005_000015.mp4\"\n",
    "video_url = \"./data/test01.mp4\"\n",
    "# Assuming 'my_video.mp4' is in the same directory as the notebook\n",
    "Video(video_url, width=640, height=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03d69707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Describe this video in detail\n",
      "Assistant: The video is titled \"The 100 Best Places to Visit in the World\" and is part of a series of videos that cover various topics related to travel and tourism. The title of the video is written in a large, bold font at the top of the video. The content of the video is divided into\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"video\", \"path\": video_url},\n",
    "            {\"type\": \"text\", \"text\": \"Describe this video in detail\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(g_device, dtype=torch.bfloat16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=64)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "print(generated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How many dogs are there\n",
      "Assistant: There are 10 dogs\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"video\", \"path\": video_url},\n",
    "            {\"type\": \"text\", \"text\": \"How many dogs are there\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(g_device, dtype=torch.bfloat16)\n",
    "\n",
    "generated_ids = model.generate(**inputs, do_sample=False, max_new_tokens=64)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "print(generated_texts[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_playgrounds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
