{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0e698b",
   "metadata": {},
   "source": [
    "# FreeNeRF: Improving Few-shot Neural Rendering with Free Frequency Regularization\n",
    "\n",
    "- Ref: \n",
    "    - https://arxiv.org/abs/2303.07418\n",
    "    - https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code/tree/main/FreeNeRF_Improving_Few_shot_Neural_Rendering_with_Free_Frequency_Regularization\n",
    "\n",
    "- Conda env : [gsplat](../gsplat/README.md#setup-a-conda-environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c4eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchshow as ts\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7160424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping already downloaded file ./temp/data/training_data.pkl\n",
      "Skipping already downloaded file ./temp/data/testing_data.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./temp/data/testing_data.pkl'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download Data\n",
    "Path('./temp/data').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1hH7NhaXxIthO9-FeT16fvpf_MVIhf41J'\n",
    "train_data_path = './temp/data/training_data.pkl'\n",
    "gdown.download(url, train_data_path, quiet=False, resume=True)\n",
    "\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=16M64h0KKgFKhM8hJDpqd15YWYhafUs2Q'\n",
    "test_data_path = './temp/data/testing_data.pkl'\n",
    "gdown.download(url, test_data_path, quiet=False, resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c95d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model_path = './temp/09_FreeNeRF_models/'\n",
    "g_video_path = './temp/09_FreeNeRF_novel_views/'\n",
    "fps = 10\n",
    "Path(g_model_path).mkdir(exist_ok=True, parents=True)\n",
    "Path(g_video_path).mkdir(exist_ok=True, parents=True)\n",
    "training_dataset = torch.from_numpy(np.load('./temp/data/training_data.pkl', allow_pickle=True))\n",
    "testing_dataset = torch.from_numpy(np.load('./temp/data/testing_data.pkl', allow_pickle=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0552a80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory allocated on MPS: 0 bytes\n",
      "Driver memory allocated on MPS: 393216 bytes\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    g_device = torch.device(\"mps\")\n",
    "    print(f\"Current memory allocated on MPS: {torch.mps.current_allocated_memory()} bytes\")\n",
    "    print(f\"Driver memory allocated on MPS: {torch.mps.driver_allocated_memory()} bytes\")\n",
    "elif torch.cuda.is_available():\n",
    "    g_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    g_device = torch.device(\"cpu\")\n",
    "print(g_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b6eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class NerfModel(nn.Module):\n",
    "    def __init__(self, embedding_dim_pos=16, embedding_dim_direction=4, hidden_dim=128, T=40_000):\n",
    "        super(NerfModel, self).__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(nn.Linear(embedding_dim_pos * 6 + 3, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), )\n",
    "        self.block2 = nn.Sequential(nn.Linear(embedding_dim_pos * 6 + hidden_dim + 3, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim), nn.ReLU(),\n",
    "                                    nn.Linear(hidden_dim, hidden_dim + 1), )\n",
    "        self.block3 = nn.Sequential(nn.Linear(embedding_dim_direction * 6 + hidden_dim + 3, hidden_dim // 2),\n",
    "                                    nn.ReLU(), )\n",
    "        self.block4 = nn.Sequential(nn.Linear(hidden_dim // 2, 3), nn.Sigmoid(), )\n",
    "\n",
    "        self.embedding_dim_pos = embedding_dim_pos\n",
    "        self.embedding_dim_direction = embedding_dim_direction\n",
    "        self.relu = nn.ReLU()\n",
    "        self.T = T\n",
    "\n",
    "    def positional_encoding(self, x, L, step, is_pos=False):\n",
    "        out = [x]\n",
    "        for j in range(L):\n",
    "            out.append(torch.sin(2 ** j * x))\n",
    "            out.append(torch.cos(2 ** j * x))\n",
    "        out = torch.cat(out, dim=1)\n",
    "\n",
    "        Lmax = 2 * 3 * L + 3\n",
    "        if is_pos:\n",
    "            out[:, int(step / self.T * Lmax) + 3:] = 0.\n",
    "        return out\n",
    "\n",
    "    def forward(self, o, d, step):\n",
    "        emb_x = self.positional_encoding(o, self.embedding_dim_pos, step, is_pos=True)\n",
    "        emb_d = self.positional_encoding(d, self.embedding_dim_direction, step, is_pos=False)\n",
    "        h = self.block1(emb_x)\n",
    "        tmp = self.block2(torch.cat((h, emb_x), dim=1))\n",
    "        h, sigma = tmp[:, :-1], torch.nn.functional.softplus(tmp[:, -1])\n",
    "        h = self.block3(torch.cat((h, emb_d), dim=1))\n",
    "        c = self.block4(h)\n",
    "        return c, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe5712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering\n",
    "\n",
    "def compute_accumulated_transmittance(alphas):\n",
    "    accumulated_transmittance = torch.cumprod(alphas, 1)\n",
    "    return torch.cat((torch.ones((accumulated_transmittance.shape[0], 1), device=alphas.device),\n",
    "                      accumulated_transmittance[:, :-1]), dim=-1)\n",
    "\n",
    "\n",
    "def render_rays(nerf_model, ray_origins, ray_directions, step, hn=0, hf=0.5, nb_bins=192):\n",
    "    device = ray_origins.device\n",
    "    t = torch.linspace(hn, hf, nb_bins, device=device).expand(ray_origins.shape[0], nb_bins)\n",
    "    # Perturb sampling along each ray.\n",
    "    mid = (t[:, :-1] + t[:, 1:]) / 2.\n",
    "    lower = torch.cat((t[:, :1], mid), -1)\n",
    "    upper = torch.cat((mid, t[:, -1:]), -1)\n",
    "    u = torch.rand(t.shape, device=device)\n",
    "    t = lower + (upper - lower) * u  # [batch_size, nb_bins]\n",
    "    delta = torch.cat((t[:, 1:] - t[:, :-1], torch.tensor([1e10], device=device).expand(ray_origins.shape[0], 1)), -1)\n",
    "\n",
    "    x = ray_origins.unsqueeze(1) + t.unsqueeze(2) * ray_directions.unsqueeze(1)  # [batch_size, nb_bins, 3]\n",
    "    ray_directions = ray_directions.expand(nb_bins, ray_directions.shape[0], 3).transpose(0, 1)\n",
    "    colors, sigma = nerf_model(x.reshape(-1, 3), ray_directions.reshape(-1, 3), step)\n",
    "    colors = colors.reshape(x.shape)\n",
    "    sigma = sigma.reshape(x.shape[:-1])\n",
    "\n",
    "    alpha = 1 - torch.exp(-sigma * delta)  # [batch_size, nb_bins]\n",
    "    weights = compute_accumulated_transmittance(1 - alpha).unsqueeze(2) * alpha.unsqueeze(2)\n",
    "    c = (weights * colors).sum(dim=1)  # Pixel values\n",
    "    weight_sum = weights.sum(-1).sum(-1)  # Regularization for white background\n",
    "    return c + 1 - weight_sum.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba60b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def test(nerf_model, hn, hf, dataset, chunk_size=10, img_index=0, nb_bins=192, H=400, W=400):\n",
    "#     ray_origins = dataset[img_index * H * W: (img_index + 1) * H * W, :3]\n",
    "#     ray_directions = dataset[img_index * H * W: (img_index + 1) * H * W, 3:6]\n",
    "\n",
    "#     data = []\n",
    "#     for i in range(int(np.ceil(H / chunk_size))):\n",
    "#         ray_origins_ = ray_origins[i * W * chunk_size: (i + 1) * W * chunk_size].to(g_device)\n",
    "#         ray_directions_ = ray_directions[i * W * chunk_size: (i + 1) * W * chunk_size].to(g_device)\n",
    "#         regenerated_px_values = render_rays(nerf_model, ray_origins_, ray_directions_, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "#         data.append(regenerated_px_values.cpu())\n",
    "#     img_t = torch.cat(data).reshape(H, W, 3)\n",
    "#     return img_t\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(nerf_model, hn, hf, dataset, step, chunk_size=10, img_index=0, nb_bins=192, H=400, W=400):\n",
    "    ray_origins = dataset[img_index * H * W: (img_index + 1) * H * W, :3]\n",
    "    ray_directions = dataset[img_index * H * W: (img_index + 1) * H * W, 3:6]\n",
    "\n",
    "    data = []\n",
    "    for i in range(int(np.ceil(H / chunk_size))):\n",
    "        ray_origins_ = ray_origins[i * W * chunk_size: (i + 1) * W * chunk_size].to(g_device)\n",
    "        ray_directions_ = ray_directions[i * W * chunk_size: (i + 1) * W * chunk_size].to(g_device)\n",
    "        regenerated_px_values = render_rays(nerf_model, ray_origins_, ray_directions_, step, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "        data.append(regenerated_px_values)\n",
    "    img = torch.cat(data).data.cpu().numpy().reshape(H, W, 3)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.savefig(f'{g_video_path}/img_{img_index}_v1.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def sample_batch(data, batch_size, device):\n",
    "    idx = torch.randperm(data.shape[0])[:batch_size]\n",
    "    return torch.from_numpy(data[idx]).to(device)\n",
    "\n",
    "# def train(nerf_model, optimizer, training_data, nb_epochs, batch_size, device='cpu', hn=0, hf=1, nb_bins=192):\n",
    "#     training_loss = []\n",
    "#     for step in tqdm(range(nb_epochs)):\n",
    "#         batch = sample_batch(training_data, batch_size, device)\n",
    "#         rays_o = batch[:, :3].to(device)\n",
    "#         rays_d = batch[:, 3:6].to(device)\n",
    "#         ground_truth_px_values = batch[:, 6:].to(device)\n",
    "\n",
    "#         regenerated_px_values = render_rays(nerf_model, rays_o, rays_d, step, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "#         loss = ((ground_truth_px_values - regenerated_px_values) ** 2).sum()\n",
    "#         training_loss.append(loss.item())\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if step % 100 or step == nb_epochs - 1:\n",
    "#             _model_path = os.path.join(g_model_path, f'nerf_model_{step:03d}.pth')\n",
    "#             torch.save(nerf_model.state_dict(), _model_path)\n",
    "#     return training_loss\n",
    "\n",
    "def train(nerf_model, optimizer, training_data, nb_epochs, batch_size, device='cpu', hn=0, hf=1, nb_bins=192):\n",
    "    training_loss = []\n",
    "    for step in tqdm(range(nb_epochs)):\n",
    "        batch = sample_batch(training_data, batch_size, device)\n",
    "        rays_o = batch[:, :3].to(device)\n",
    "        rays_d = batch[:, 3:6].to(device)\n",
    "        ground_truth_px_values = batch[:, 6:].to(device)\n",
    "\n",
    "        regenerated_px_values = render_rays(nerf_model, rays_o, rays_d, step, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "        loss = ((ground_truth_px_values - regenerated_px_values) ** 2).sum()\n",
    "        training_loss.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if step % 10000 or step == nb_epochs - 1:\n",
    "        #     _model_path = os.path.join(g_model_path, f'nerf_model_{step:03d}.pth')\n",
    "        #     torch.save(nerf_model.state_dict(), _model_path)\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d2b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NerfModel(hidden_dim=256).to(g_device)\n",
    "# model_optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(model_optimizer, milestones=[2, 4, 8], gamma=0.5)\n",
    "\n",
    "# data_loader = DataLoader(training_dataset, batch_size=1024, shuffle=True)\n",
    "# train(model, model_optimizer, scheduler, data_loader, nb_epochs=16, device=g_device, hn=2, hf=6, nb_bins=192, H=400,W=400)\n",
    "\n",
    "\n",
    "# # for img_index in range(200):\n",
    "# #     test(model, 2, 6, testing_dataset, img_index=img_index, nb_bins=192, H=800, W=800)\n",
    "# imgT_lst = []\n",
    "# for idx in tqdm(range(200), desc=\"Validation\"):\n",
    "#         imgT_lst.append(test(model, 2, 6, testing_dataset, chunk_size = 10, img_index=idx, nb_bins=192, H = 400, W = 400 ).unsqueeze(0))\n",
    "# img_t = (torch.cat(imgT_lst) * 255).to(torch.uint8)\n",
    "# _video_path = os.path.join(g_video_path,  f'nerf_model_test.mp4')\n",
    "# torchvision.io.write_video(_video_path, img_t, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15999b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [3:49:18<00:00,  5.81it/s]  \n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00025451183..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00015383959..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0001538992..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.000112473965..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [6.0081482e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00014710426..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [6.532669e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [7.879734e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [4.5657158e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [3.7014484e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [3.2663345e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [4.506111e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [4.374981e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [3.325939e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [4.518032e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [6.723404e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00011014938..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [6.151199e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [6.592274e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.000120043755..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [9.3102455e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [9.649992e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00010514259..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00014424324..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00015342236..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00015556812..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00018966198..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [9.262562e-05..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00013279915..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00021457672..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00022262335..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00040841103..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00031411648..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00030112267..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00028145313..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0009204149..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0008458495..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0013449192..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0015515089..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0014188886..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0022566319..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0020183325..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0026176572..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0020973682..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0013674498..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0013071895..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0015141964..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0010938048..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00079131126..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00082468987..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0007252693..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0005580187..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00029838085..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0003247857..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00027102232..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00066691637..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0006092191..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00049096346..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00075113773..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0007067323..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0013679266..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00112468..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0017784238..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0017188787..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0018437505..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0011879206..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0012577176..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0009952784..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00072801113..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.000505805..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00042957067..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0006877184..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0006902218..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0015562773..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.000590384..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00081676245..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0007197261..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00080162287..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00067031384..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0006055832..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00030881166..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00036096573..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0002206564..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00016504526..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.000300169..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00024056435..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00018465519..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00013566017..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00022363663..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00013393164..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00015878677..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00014996529..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00015890598..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00017756224..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00025612116..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00025004148..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00026232004..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0003631711..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00024563074..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0003579855..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0003501773..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0002478361..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0002564788..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00074887276..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00052571297..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00054365396..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00047808886..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0002925992..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.000346303..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00027698278..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00038397312..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0003556013..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0004390478..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00027406216..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00021207333..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00052428246..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0004956126..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0007395148..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0008507371..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0027188659..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0046773553..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.006314993..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.002341926..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.002818048..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0017710924..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0014267564..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00097227097..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0010356903..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0008356571..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0007287264..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0010655522..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0007996559..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.001154244..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0012667179..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0009275079..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0007969737..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00087463856..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00058192015..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00044107437..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0001860857..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00025558472..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00021201372..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0001860857..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00031459332..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00046300888..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00030082464..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00023800135..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0003119707..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0002824068..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00019276142..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00022006035..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00016856194..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00013530254..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00016331673..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00014126301..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0001090765..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0001705885..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00033795834..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00018751621..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0001822114..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00017559528..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00031232834..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00024354458..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0003400445..1.0000001].\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00018757582..1.0000001].\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 80_000\n",
    "\n",
    "img0 = training_dataset[26 * 400 * 400:(26 + 1) * 400 * 400]\n",
    "img2 = training_dataset[86 * 400 * 400:(86 + 1) * 400 * 400]\n",
    "img3 = training_dataset[2 * 400 * 400:(2 + 1) * 400 * 400]\n",
    "img4 = training_dataset[55 * 400 * 400:(55 + 1) * 400 * 400]\n",
    "img5 = training_dataset[75 * 400 * 400:(75 + 1) * 400 * 400]\n",
    "img6 = training_dataset[93 * 400 * 400:(93 + 1) * 400 * 400]\n",
    "img7 = training_dataset[16 * 400 * 400:(16 + 1) * 400 * 400]\n",
    "img8 = training_dataset[73 * 400 * 400:(73 + 1) * 400 * 400]\n",
    "\n",
    "training_data = np.concatenate((img0, img2, img3, img4, img5, img6, img7, img8))\n",
    "model = NerfModel(hidden_dim=256, T=nb_epochs // 2).to(g_device)\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "train(model, model_optimizer, training_data, nb_epochs, 1024, device=g_device, hn=2, hf=6, nb_bins=192)\n",
    "_model_path = os.path.join(g_model_path, f'nerf_model_final.pth')\n",
    "torch.save(model.state_dict(), _model_path)\n",
    "\n",
    "for img_index in range(200):\n",
    "        test(model, 2, 6, testing_dataset, nb_epochs, img_index=img_index, nb_bins=192, H=400, W=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12c6e724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 200/200 [29:39<00:00,  8.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# @torch.no_grad()\n",
    "# def test(nerf_model, hn, hf, dataset, chunk_size=10, img_index=0, nb_bins=192, H=400, W=400):\n",
    "#     ray_origins = dataset[img_index * H * W: (img_index + 1) * H * W, :3]\n",
    "#     ray_directions = dataset[img_index * H * W: (img_index + 1) * H * W, 3:6]\n",
    "\n",
    "#     data = []\n",
    "#     for i in range(int(np.ceil(H / chunk_size))):\n",
    "#         ray_origins_ = ray_origins[i * W * chunk_size: (i + 1) * W * chunk_size].to(g_device)\n",
    "#         ray_directions_ = ray_directions[i * W * chunk_size: (i + 1) * W * chunk_size].to(g_device)\n",
    "#         regenerated_px_values = render_rays(nerf_model, ray_origins_, ray_directions_, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "#         data.append(regenerated_px_values.cpu())\n",
    "#     img_t = torch.cat(data).reshape(H, W, 3)\n",
    "#     return img_t\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(nerf_model, hn, hf, dataset, step, chunk_size=10, img_index=0, nb_bins=192, H=400, W=400):\n",
    "    ray_origins = dataset[img_index * H * W: (img_index + 1) * H * W, :3]\n",
    "    ray_directions = dataset[img_index * H * W: (img_index + 1) * H * W, 3:6]\n",
    "\n",
    "    data = []\n",
    "    for i in range(int(np.ceil(H / chunk_size))):\n",
    "        ray_origins_ = ray_origins[i * W * chunk_size: (i + 1) * W * chunk_size].to(g_device)\n",
    "        ray_directions_ = ray_directions[i * W * chunk_size: (i + 1) * W * chunk_size].to(g_device)\n",
    "        regenerated_px_values = render_rays(nerf_model, ray_origins_, ray_directions_, step, hn=hn, hf=hf, nb_bins=nb_bins)\n",
    "        data.append(regenerated_px_values.data.cpu())\n",
    "    img_t = torch.cat(data).reshape(H, W, 3)\n",
    "    return img_t\n",
    "\n",
    "model.eval()\n",
    "imgT_lst = []\n",
    "for idx in tqdm(range(200), desc=\"Validation\"):\n",
    "    imgT_lst.append(test(model, 2, 6, testing_dataset, nb_epochs, chunk_size = 10, img_index=idx, nb_bins=192, H = 400, W = 400 ).unsqueeze(0))\n",
    "img_t = (torch.cat(imgT_lst) * 255).to(torch.uint8)\n",
    "_video_path = os.path.join(g_video_path,  f'nerf_model_test.mp4')\n",
    "torchvision.io.write_video(_video_path, img_t, fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45988d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
