{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534e04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Defining a time-dependent score-based model (double click to expand or collapse)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, Subset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "# from torchvision.datasets import MNIST\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import make_grid\n",
    "import torchshow as ts\n",
    "\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from scipy import integrate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from pathlib import Path\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f44ee2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Current memory allocated on MPS: {torch.mps.current_allocated_memory()} bytes\")\n",
    "    print(f\"Driver memory allocated on MPS: {torch.mps.driver_allocated_memory()} bytes\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d774c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Set up the SDE\n",
    "def marginal_prob_std(t, sigma):\n",
    "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "\n",
    "  Returns:\n",
    "    The standard deviation.\n",
    "  \"\"\"\n",
    "  # t = torch.tensor(t, device=device, dtype=torch.float32) # KHJ : : To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "  # t = torch.tensor(t.clone().detach().requires_grad_(True), device=device, dtype=torch.float32)\n",
    "  _t = t.clone().detach()\n",
    "  return torch.sqrt((sigma**(2 * _t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "\n",
    "  Returns:\n",
    "    The vector of diffusion coefficients.\n",
    "  \"\"\"\n",
    "  # return torch.tensor(sigma**t, device=device, dtype=torch.float32) # KHJ : To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "  _t = t.clone().detach()\n",
    "  # return torch.tensor(sigma** _t, device=device, dtype=torch.float32)\n",
    "  return sigma** _t\n",
    "\n",
    "sigma =  25.0#@param {'type':'number'}\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f60d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the loss function (double click to expand or collapse)\n",
    "\n",
    "def loss_fn(model, x, y, marginal_prob_std, eps=1e-5):\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance that represents a\n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "  \"\"\"\n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
    "  z = torch.randn_like(x)\n",
    "  std = marginal_prob_std(random_t)\n",
    "  perturbed_x = x + z * std[:, None, None, None]\n",
    "  score = model(perturbed_x, random_t, y)\n",
    "  loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37825e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"\n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed\n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    return self.dense(x)[..., None, None]\n",
    "\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256, in_channel = 1, num_labels=None):\n",
    "    \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "    Args:\n",
    "      marginal_prob_std: A function that takes time t and gives the standard\n",
    "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "      channels: The number of channels for feature maps of each resolution.\n",
    "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Gaussian random feature embedding layer for time\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "    # Encoding layers where the resolution decreases\n",
    "    self.conv1 = nn.Conv2d(in_channel, channels[0], 3, stride=1, padding = 1, bias=False)\n",
    "    self.dense1 = Dense(embed_dim, channels[0])\n",
    "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, padding = 1, bias=False)\n",
    "    self.dense2 = Dense(embed_dim, channels[1])\n",
    "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, padding = 1, bias=False)\n",
    "    self.dense3 = Dense(embed_dim, channels[2])\n",
    "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, padding = 1, bias=False)\n",
    "    self.dense4 = Dense(embed_dim, channels[3])\n",
    "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "\n",
    "    # Decoding layers where the resolution increases\n",
    "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False, padding=1, output_padding=1)\n",
    "    self.dense5 = Dense(embed_dim, channels[2])\n",
    "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, padding=1, output_padding=1)\n",
    "    self.dense6 = Dense(embed_dim, channels[1])\n",
    "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, padding=1, output_padding=1)\n",
    "    self.dense7 = Dense(embed_dim, channels[0])\n",
    "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "    self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], in_channel, 3, stride=1, padding=1)\n",
    "\n",
    "    # The swish activation function\n",
    "    self.act = lambda x: x * torch.sigmoid(x)\n",
    "    self.marginal_prob_std = marginal_prob_std\n",
    "\n",
    "    if num_labels is not None:\n",
    "      self.label_emb = nn.Embedding(num_labels, embed_dim)\n",
    "\n",
    "  def forward(self, x, t, labels=None):\n",
    "    # Obtain the Gaussian random feature embedding for t\n",
    "    embed = self.act(self.embed(t))\n",
    "    if labels is not None:\n",
    "      embed += self.label_emb(labels)\n",
    "    # Encoding path\n",
    "    h1 = self.conv1(x)\n",
    "    ## Incorporate information from t\n",
    "    h1 += self.dense1(embed)\n",
    "    ## Group normalization\n",
    "    h1 = self.gnorm1(h1)\n",
    "    h1 = self.act(h1)\n",
    "    h2 = self.conv2(h1)\n",
    "    h2 += self.dense2(embed)\n",
    "    h2 = self.gnorm2(h2)\n",
    "    h2 = self.act(h2)\n",
    "    h3 = self.conv3(h2)\n",
    "    h3 += self.dense3(embed)\n",
    "    h3 = self.gnorm3(h3)\n",
    "    h3 = self.act(h3)\n",
    "    h4 = self.conv4(h3)\n",
    "    h4 += self.dense4(embed)\n",
    "    h4 = self.gnorm4(h4)\n",
    "    h4 = self.act(h4)\n",
    "\n",
    "    # Decoding path\n",
    "    h = self.tconv4(h4)\n",
    "    ## Skip connection from the encoding path\n",
    "    h += self.dense5(embed)\n",
    "    h = self.tgnorm4(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv3(torch.cat([h, h3], dim=1))\n",
    "    h += self.dense6(embed)\n",
    "    h = self.tgnorm3(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv2(torch.cat([h, h2], dim=1))\n",
    "    h += self.dense7(embed)\n",
    "    h = self.tgnorm2(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "    # Normalize output\n",
    "    h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58612858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "## Unet network model\n",
    "# Ref: https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code/blob/main/Denoising_Diffusion_Probabilistic_Models/unet.py\n",
    "\n",
    "def get_timestep_embedding(timesteps, embedding_dim: int):\n",
    "    \"\"\"\n",
    "    Retrieved from https://github.com/hojonathanho/diffusion/blob/master/diffusion_tf/nn.py#LL90C1-L109C13\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=timesteps.device) * -emb)\n",
    "    emb = timesteps.type(torch.float32)[:, None] * emb[None, :]\n",
    "    emb = torch.concat([torch.sin(emb), torch.cos(emb)], axis=1)\n",
    "\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
    "\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim), f\"{emb.shape}\"\n",
    "    return emb\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "\n",
    "    def __init__(self, C):\n",
    "        \"\"\"\n",
    "        :param C (int): number of input and output channels\n",
    "        \"\"\"\n",
    "        super(Downsample, self).__init__()\n",
    "        self.conv = nn.Conv2d(C, C, 3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.conv(x)\n",
    "        assert x.shape == (B, C, H // 2, W // 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "\n",
    "    def __init__(self, C):\n",
    "        \"\"\"\n",
    "        :param C (int): number of input and output channels\n",
    "        \"\"\"\n",
    "        super(Upsample, self).__init__()\n",
    "        self.conv = nn.Conv2d(C, C, 3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        x = nn.functional.interpolate(x, size=None, scale_factor=2, mode='nearest')\n",
    "\n",
    "        x = self.conv(x)\n",
    "        assert x.shape == (B, C, H * 2, W * 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Nin(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, scale=1e-10):\n",
    "        super(Nin, self).__init__()\n",
    "\n",
    "        n = (in_dim + out_dim) / 2\n",
    "        limit = np.sqrt(3 * scale / n)\n",
    "        self.W = torch.nn.Parameter(torch.zeros((in_dim, out_dim), dtype=torch.float32\n",
    "                                                ).uniform_(-limit, limit))\n",
    "        self.b = torch.nn.Parameter(torch.zeros((1, out_dim, 1, 1), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.einsum('bchw, co->bohw', x, self.W) + self.b\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, out_ch, dropout_rate=0.1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
    "        self.dense = nn.Linear(512, out_ch)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1)\n",
    "\n",
    "        if not (in_ch == out_ch):\n",
    "            self.nin = Nin(in_ch, out_ch)\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.nonlinearity = torch.nn.SiLU()\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        \"\"\"\n",
    "        :param x: (B, C, H, W)\n",
    "        :param temb: (B, dim)\n",
    "        \"\"\"\n",
    "\n",
    "        h = self.nonlinearity(nn.functional.group_norm(x, num_groups=32))\n",
    "        h = self.conv1(h)\n",
    "\n",
    "        # add in timestep embedding\n",
    "        h += self.dense(self.nonlinearity(temb))[:, :, None, None]\n",
    "\n",
    "        h = self.nonlinearity(nn.functional.group_norm(h, num_groups=32))\n",
    "        h = nn.functional.dropout(h, p=self.dropout_rate)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        if not (x.shape[1] == h.shape[1]):\n",
    "            x = self.nin(x)\n",
    "\n",
    "        assert x.shape == h.shape\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, ch):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "\n",
    "        self.Q = Nin(ch, ch)\n",
    "        self.K = Nin(ch, ch)\n",
    "        self.V = Nin(ch, ch)\n",
    "\n",
    "        self.ch = ch\n",
    "\n",
    "        self.nin = Nin(ch, ch, scale=0.)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert C == self.ch\n",
    "\n",
    "        h = nn.functional.group_norm(x, num_groups=32)\n",
    "        q = self.Q(h)\n",
    "        k = self.K(h)\n",
    "        v = self.V(h)\n",
    "\n",
    "        w = torch.einsum('bchw,bcHW->bhwHW', q, k) * (int(C) ** (-0.5))  # [B, H, W, H, W]\n",
    "        w = torch.reshape(w, [B, H, W, H * W])\n",
    "        w = torch.nn.functional.softmax(w, dim=-1)\n",
    "        w = torch.reshape(w, [B, H, W, H, W])\n",
    "\n",
    "        h = torch.einsum('bhwHW,bcHW->bchw', w, v)\n",
    "        h = self.nin(h)\n",
    "\n",
    "        assert h.shape == x.shape\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, marginal_prob_std = None, ch=128, in_channel=1, num_labels=None):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.marginal_prob_std = marginal_prob_std\n",
    "        self.ch = ch\n",
    "        self.linear1 = nn.Linear(ch, 4 * ch)\n",
    "        self.linear2 = nn.Linear(4 * ch, 4 * ch)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channel, ch, 3, stride=1, padding=1)\n",
    "\n",
    "        self.down = nn.ModuleList([ResNetBlock(ch, 1 * ch),\n",
    "                                   ResNetBlock(1 * ch, 1 * ch),\n",
    "                                   Downsample(1 * ch),\n",
    "                                   ResNetBlock(1 * ch, 2 * ch),\n",
    "                                   AttentionBlock(2 * ch),\n",
    "                                   ResNetBlock(2 * ch, 2 * ch),\n",
    "                                   AttentionBlock(2 * ch),\n",
    "                                   Downsample(2 * ch),\n",
    "                                   ResNetBlock(2 * ch, 2 * ch),\n",
    "                                   ResNetBlock(2 * ch, 2 * ch),\n",
    "                                   Downsample(2 * ch),\n",
    "                                   ResNetBlock(2 * ch, 2 * ch),\n",
    "                                   ResNetBlock(2 * ch, 2 * ch)])\n",
    "\n",
    "        self.middle = nn.ModuleList([ResNetBlock(2 * ch, 2 * ch),\n",
    "                                     AttentionBlock(2 * ch),\n",
    "                                     ResNetBlock(2 * ch, 2 * ch)])\n",
    "\n",
    "        self.up = nn.ModuleList([ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 Upsample(2 * ch),\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 Upsample(2 * ch),\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 AttentionBlock(2 * ch),\n",
    "                                 ResNetBlock(4 * ch, 2 * ch),\n",
    "                                 AttentionBlock(2 * ch),\n",
    "                                 ResNetBlock(3 * ch, 2 * ch),\n",
    "                                 AttentionBlock(2 * ch),\n",
    "                                 Upsample(2 * ch),\n",
    "                                 ResNetBlock(3 * ch, ch),\n",
    "                                 ResNetBlock(2 * ch, ch),\n",
    "                                 ResNetBlock(2 * ch, ch)])\n",
    "\n",
    "        self.final_conv = nn.Conv2d(ch, in_channel, 3, stride=1, padding=1)\n",
    "\n",
    "        if num_labels is not None:\n",
    "            self.label_emb = nn.Embedding(num_labels, self.ch * 4)\n",
    "\n",
    "    def forward(self, x, t, labels=None):\n",
    "        \"\"\"\n",
    "        :param x: (torch.Tensor) batch of images [B, C, H, W]\n",
    "        :param t: (torch.Tensor) tensor of time steps (torch.long) [B]\n",
    "        \"\"\"\n",
    "\n",
    "        temb = get_timestep_embedding(t, self.ch)\n",
    "        temb = torch.nn.functional.silu(self.linear1(temb))\n",
    "        temb = self.linear2(temb)\n",
    "        assert temb.shape == (t.shape[0], self.ch * 4)\n",
    "        if labels is not None:\n",
    "            temb += self.label_emb(labels)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "\n",
    "        # Down\n",
    "        x2 = self.down[0](x1, temb)\n",
    "        x3 = self.down[1](x2, temb)\n",
    "        x4 = self.down[2](x3)\n",
    "        x5 = self.down[3](x4, temb)\n",
    "        x6 = self.down[4](x5)  # Attention\n",
    "        x7 = self.down[5](x6, temb)\n",
    "        x8 = self.down[6](x7)  # Attention\n",
    "        x9 = self.down[7](x8)\n",
    "        x10 = self.down[8](x9, temb)\n",
    "        x11 = self.down[9](x10, temb)\n",
    "        x12 = self.down[10](x11)\n",
    "        x13 = self.down[11](x12, temb)\n",
    "        x14 = self.down[12](x13, temb)\n",
    "\n",
    "        # Middle\n",
    "        x = self.middle[0](x14, temb)\n",
    "        x = self.middle[1](x)\n",
    "        x = self.middle[2](x, temb)\n",
    "\n",
    "        # Up\n",
    "        x = self.up[0](torch.cat((x, x14), dim=1), temb)\n",
    "        x = self.up[1](torch.cat((x, x13), dim=1), temb)\n",
    "        x = self.up[2](torch.cat((x, x12), dim=1), temb)\n",
    "        x = self.up[3](x)\n",
    "        x = self.up[4](torch.cat((x, x11), dim=1), temb)\n",
    "        x = self.up[5](torch.cat((x, x10), dim=1), temb)\n",
    "        x = self.up[6](torch.cat((x, x9), dim=1), temb)\n",
    "        x = self.up[7](x)\n",
    "        x = self.up[8](torch.cat((x, x8), dim=1), temb)\n",
    "        x = self.up[9](x)\n",
    "        x = self.up[10](torch.cat((x, x6), dim=1), temb)\n",
    "        x = self.up[11](x)\n",
    "        x = self.up[12](torch.cat((x, x4), dim=1), temb)\n",
    "        x = self.up[13](x)\n",
    "        x = self.up[14](x)\n",
    "        x = self.up[15](torch.cat((x, x3), dim=1), temb)\n",
    "        x = self.up[16](torch.cat((x, x2), dim=1), temb)\n",
    "        x = self.up[17](torch.cat((x, x1), dim=1), temb)\n",
    "\n",
    "        x = nn.functional.silu(nn.functional.group_norm(x, num_groups=32))\n",
    "        x = self.final_conv(x)\n",
    "        if self.marginal_prob_std is not None:\n",
    "            x = x / self.marginal_prob_std(t)[:, None, None, None]\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "in_ch = 1\n",
    "score_model = UNet(marginal_prob_std=marginal_prob_std_fn, in_channel=in_ch, num_labels=10)\n",
    "x = torch.rand((1, in_ch, 64, 64), dtype=torch.float32)\n",
    "t = torch.rand((1,), dtype=torch.float32)\n",
    "l = torch.tensor([1])\n",
    "\n",
    "y = score_model(x, t, l)\n",
    "\n",
    "print(x.shape)\n",
    "print(t.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff9c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the Euler-Maruyama sampler (double click to expand or collapse)\n",
    "\n",
    "## The number of sampling steps.\n",
    "num_steps =  500#@param {'type':'integer'}\n",
    "def Euler_Maruyama_sampler(score_model,\n",
    "                           marginal_prob_std,\n",
    "                           diffusion_coeff,\n",
    "                           batch_size=64,\n",
    "                           img_shape = (1, 32, 32),\n",
    "                           num_steps=num_steps,\n",
    "                           device='cuda',\n",
    "                           eps=1e-3,\n",
    "                           labels = None,\n",
    "                           gamma = 3.0):\n",
    "  \"\"\"Generate samples from score-based models with the Euler-Maruyama solver.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps.\n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "\n",
    "  Returns:\n",
    "    Samples.\n",
    "  \"\"\"\n",
    "  if labels is not None:\n",
    "     batch_size = min(batch_size, len(labels))\n",
    "     labels = labels[:batch_size]\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  init_x = torch.randn((batch_size,) + img_shape, device=device) \\\n",
    "    * marginal_prob_std(t)[:, None, None, None]\n",
    "  time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "  step_size = time_steps[0] - time_steps[1]\n",
    "  x = init_x\n",
    "  with torch.no_grad():\n",
    "    # for time_step in tqdm.tqdm(time_steps):\n",
    "    for time_step in time_steps:\n",
    "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "      g = diffusion_coeff(batch_time_step)\n",
    "\n",
    "      score_model.eval()\n",
    "      with torch.no_grad():\n",
    "          score = score_model(x, batch_time_step, labels)\n",
    "          score_uncond = score_model(x, batch_time_step)\n",
    "          score = score_uncond + gamma * (score - score_uncond)\n",
    "      score_model.train()\n",
    "\n",
    "      mean_x = x + (g**2)[:, None, None, None] * score * step_size\n",
    "      # mean_x = x + (g**2)[:, None, None, None] * score_model(x, batch_time_step) * step_size\n",
    "      x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)\n",
    "  # Do not include any noise in the last sampling step.\n",
    "  return mean_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aeaeb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the Predictor-Corrector sampler (double click to expand or collapse)\n",
    "\n",
    "signal_to_noise_ratio = 0.16 #@param {'type':'number'}\n",
    "\n",
    "## The number of sampling steps.\n",
    "num_steps =  500#@param {'type':'integer'}\n",
    "def pc_sampler(score_model,\n",
    "               marginal_prob_std,\n",
    "               diffusion_coeff,\n",
    "               batch_size=64,\n",
    "               img_shape = (1, 32, 32),\n",
    "               num_steps=num_steps,\n",
    "               snr=signal_to_noise_ratio,\n",
    "               device='cuda',\n",
    "               eps=1e-3,\n",
    "               labels = None,\n",
    "               gamma = 3.0):\n",
    "  \"\"\"Generate samples from score-based models with Predictor-Corrector method.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation\n",
    "      of the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient\n",
    "      of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps.\n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "\n",
    "  Returns:\n",
    "    Samples.\n",
    "  \"\"\"\n",
    "  if labels is not None:\n",
    "     batch_size = min(batch_size, len(labels))\n",
    "     labels = labels[:batch_size]\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  init_x = torch.randn((batch_size,) + img_shape, device=device) * marginal_prob_std(t)[:, None, None, None]\n",
    "  time_steps = np.linspace(1., eps, num_steps)\n",
    "  step_size = time_steps[0] - time_steps[1]\n",
    "  x = init_x\n",
    "  with torch.no_grad():\n",
    "    # for time_step in tqdm.tqdm(time_steps):\n",
    "    for time_step in time_steps:\n",
    "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "      # Corrector step (Langevin MCMC)\n",
    "\n",
    "      # grad = score_model(x, batch_time_step)\n",
    "      score_model.eval()\n",
    "      with torch.no_grad():\n",
    "          score = score_model(x, batch_time_step, labels)\n",
    "          score_uncond = score_model(x, batch_time_step)\n",
    "          score = score_uncond + gamma * (score - score_uncond)\n",
    "      score_model.train()\n",
    "      grad = score\n",
    "\n",
    "      grad_norm = torch.norm(grad.reshape(grad.shape[0], -1), dim=-1).mean()\n",
    "      noise_norm = np.sqrt(np.prod(x.shape[1:]))\n",
    "      langevin_step_size = 2 * (snr * noise_norm / grad_norm)**2\n",
    "      x = x + langevin_step_size * grad + torch.sqrt(2 * langevin_step_size) * torch.randn_like(x)\n",
    "\n",
    "      # Predictor step (Euler-Maruyama)\n",
    "      g = diffusion_coeff(batch_time_step)\n",
    "\n",
    "      score_model.eval()\n",
    "      with torch.no_grad():\n",
    "          score = score_model(x, batch_time_step, labels)\n",
    "          score_uncond = score_model(x, batch_time_step)\n",
    "          score = score_uncond + gamma * (score - score_uncond)\n",
    "      score_model.train()\n",
    "      x_mean = x + (g**2)[:, None, None, None] * score * step_size\n",
    "      # x_mean = x + (g**2)[:, None, None, None] * score_model(x, batch_time_step) * step_size\n",
    "      x = x_mean + torch.sqrt(g**2 * step_size)[:, None, None, None] * torch.randn_like(x)\n",
    "\n",
    "    # The last step does not include any noise\n",
    "    return x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c4942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the ODE sampler (double click to expand or collapse)\n",
    "\n",
    "## The error tolerance for the black-box ODE solver\n",
    "error_tolerance = 1e-5 #@param {'type': 'number'}\n",
    "def ode_sampler(score_model,\n",
    "                marginal_prob_std,\n",
    "                diffusion_coeff,\n",
    "                batch_size=64,\n",
    "                img_shape = (1, 32, 32),\n",
    "                atol=error_tolerance,\n",
    "                rtol=error_tolerance,\n",
    "                device='cuda',\n",
    "                z=None,\n",
    "                eps=1e-3,\n",
    "                labels = None,\n",
    "                gamma = 3.0):\n",
    "  \"\"\"Generate samples from score-based models with black-box ODE solvers.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that returns the standard deviation\n",
    "      of the perturbation kernel.\n",
    "    diffusion_coeff: A function that returns the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    atol: Tolerance of absolute errors.\n",
    "    rtol: Tolerance of relative errors.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    z: The latent code that governs the final sample. If None, we start from p_1;\n",
    "      otherwise, we start from the given z.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "  \"\"\"\n",
    "  if labels is not None:\n",
    "     batch_size = min(batch_size, len(labels))\n",
    "     labels = labels[:batch_size]\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  # Create the latent code\n",
    "  if z is None:\n",
    "    init_x = torch.randn((batch_size,) + img_shape, device=device) \\\n",
    "      * marginal_prob_std(t)[:, None, None, None]\n",
    "  else:\n",
    "    init_x = z\n",
    "\n",
    "  shape = init_x.shape\n",
    "\n",
    "  def score_eval_wrapper(sample, time_steps):\n",
    "    \"\"\"A wrapper of the score-based model for use by the ODE solver.\"\"\"\n",
    "    sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
    "    time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], ))\n",
    "    # with torch.no_grad():\n",
    "    #   score = score_model(sample, time_steps)\n",
    "    score_model.eval()\n",
    "    with torch.no_grad():\n",
    "        score = score_model(sample, time_steps, labels)\n",
    "        score_uncond = score_model(sample, time_steps)\n",
    "        score = score_uncond + gamma * (score - score_uncond)\n",
    "    score_model.train()\n",
    "    return score.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
    "\n",
    "  def ode_func(t, x):\n",
    "    \"\"\"The ODE function for use by the ODE solver.\"\"\"\n",
    "    time_steps = np.ones((shape[0],)) * t\n",
    "    g = diffusion_coeff(torch.tensor(t, dtype=torch.float32)).cpu().numpy()\n",
    "    return  -0.5 * (g**2) * score_eval_wrapper(x, time_steps)\n",
    "\n",
    "  # Run the black-box ODE solver.\n",
    "  res = integrate.solve_ivp(ode_func, (1., eps), init_x.reshape(-1).cpu().numpy(), rtol=rtol, atol=atol, method='RK45')\n",
    "  # print(f\"ODE_Sampler :: Number of function evaluations: {res.nfev}\")\n",
    "  x = torch.tensor(res.y[:, -1], device=device, dtype=torch.float32 ).reshape(shape)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e08eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 1020\n",
      "the size of Label Set : 102\n",
      "------\n",
      "filtered data size : 408\n",
      "num_labels : 102\n"
     ]
    }
   ],
   "source": [
    "#@title Training (double click to expand or collapse)\n",
    "\n",
    "g_model_path = './temp/models/Score_based_Models_Pytorch_Flowers102_20_Conditional_Data_0_1/'\n",
    "g_video_path = './temp/videos/Score_based_Models_Pytorch_Flowers102_20_Conditional_Data_0_1/'\n",
    "g_log_path = './temp/logs/Score_based_Models_Pytorch_Flowers102_20_Conditional_Data_0_1/'\n",
    "Path(g_model_path).mkdir(exist_ok=True, parents=True)\n",
    "Path(g_video_path).mkdir(exist_ok=True, parents=True)\n",
    "g_writer = SummaryWriter(g_log_path)\n",
    "\n",
    "n_epochs =  50 #@param {'type':'integer'}\n",
    "## size of a mini-batch\n",
    "batch_size =  4 #@param {'type':'integer'}\n",
    "## learning rate\n",
    "lr=1e-4 #@param {'type':'number'}\n",
    "sample_batch_size = 4\n",
    "# nsample = batch_size * 5\n",
    "eval_steps = 5\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((128, 128),interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "                # transforms.Normalize(mean=(0.5), std=(0.5)) # Normalizes to [-1, 1]\n",
    "            ])\n",
    "\n",
    "dataset = datasets.Flowers102(root='../temp_data/data', split='train', download=True, transform = transform)\n",
    "in_ch = dataset[0][0].shape[0]\n",
    "img_shape = tuple(dataset[0][0].shape)\n",
    "\n",
    "# ###############\n",
    "label_set = defaultdict(list)\n",
    "\n",
    "for i, d in enumerate(dataset):\n",
    "    if len(label_set[d[1]]) < batch_size:\n",
    "        label_set[d[1]].append(i)\n",
    "\n",
    "num_labels = len(label_set)\n",
    "print(f\"Size of dataset: {len(dataset)}\")\n",
    "print(f\"the size of Label Set : {num_labels}\")\n",
    "\n",
    "label_list = []\n",
    "for l in label_set.values():\n",
    "    label_list += l\n",
    "\n",
    "\n",
    "print(\"------\")\n",
    "print(f\"filtered data size : {len(label_list)}\")\n",
    "print(f\"num_labels : {(num_labels)}\")\n",
    "###################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df9d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## size of a mini-batch\n",
    "batch_size =  4 #@param {'type':'integer'}\n",
    "## learning rate\n",
    "lr=1e-4 #@param {'type':'number'}\n",
    "\n",
    "score_model = UNet(marginal_prob_std=marginal_prob_std_fn, in_channel=in_ch, num_labels=num_labels)\n",
    "score_model = score_model.to(device)\n",
    "optimizer = Adam(score_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd61f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss: 448.780289:  30%|███       | 302/1001 [8:14:05<32:18:13, 166.37s/it]"
     ]
    }
   ],
   "source": [
    "# indices = list(range(nsample))\n",
    "# indices = label_list\n",
    "# subset_dataset = Subset(dataset, indices)\n",
    "# data_loader = torch.utils.data.DataLoader(subset_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "s_epochs = 0\n",
    "n_epochs =  1001 #50 #@param {'type':'integer'}\n",
    "sample_batch_size = 4\n",
    "eval_steps = 50\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# score_model = UNet(marginal_prob_std=marginal_prob_std_fn, in_channel=in_ch, num_labels=num_labels)\n",
    "# score_model = score_model.to(device)\n",
    "# optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "tqdm_epoch = tqdm.trange(s_epochs, n_epochs)\n",
    "best_avg_loss = float('inf')\n",
    "best_cnt = 0\n",
    "test_label = None\n",
    "\n",
    "for epoch in tqdm_epoch:\n",
    "  avg_loss = 0.\n",
    "  num_items = 0\n",
    "  for x, y in data_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    if test_label is None:\n",
    "      test_label = y.clone()\n",
    "      test_label.to(device)\n",
    "\n",
    "    if np.random.random() < 0.1:\n",
    "      y = None\n",
    "    loss = loss_fn(score_model, x, y, marginal_prob_std_fn)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    avg_loss += loss.item() * x.shape[0]\n",
    "    num_items += x.shape[0]\n",
    "\n",
    "  g_writer.add_scalar(\"Loss/AVG\", avg_loss, epoch)\n",
    "  if epoch % eval_steps == 0 or epoch == n_epochs - 1:\n",
    "    # Test image\n",
    "    # samples = ode_sampler(score_model,\n",
    "    #                       marginal_prob_std_fn,\n",
    "    #                       diffusion_coeff_fn,\n",
    "    #                       batch_size = sample_batch_size,\n",
    "    #                       img_shape=img_shape,\n",
    "    #                       device=device,\n",
    "    #                       eps=1e-2,\n",
    "    #                       labels=test_label)\n",
    "\n",
    "    # img_op = os.path.join(g_video_path, f\"ode_sampler_{epoch:03d}.jpg\")\n",
    "    # samples = (samples.to(\"cpu\") + 1) * 0.5\n",
    "    # samples.clamp(0, 1.0)\n",
    "    # ts.save(samples, img_op, ncols = 2)\n",
    "    # img_grid = make_grid(samples)\n",
    "    # g_writer.add_image('Image/ode_sampler', img_grid, global_step=epoch)\n",
    "\n",
    "    samples = pc_sampler(score_model,\n",
    "                        marginal_prob_std_fn,\n",
    "                        diffusion_coeff_fn,\n",
    "                        sample_batch_size,\n",
    "                        img_shape=img_shape,\n",
    "                        device=device,\n",
    "                        labels=test_label)\n",
    "\n",
    "    img_op = os.path.join(g_video_path, f\"pc_sampler{epoch:03d}.jpg\")\n",
    "    # samples = (samples.to(\"cpu\") + 1) * 0.5\n",
    "    samples.clamp(0, 1.0)\n",
    "    ts.save(samples, img_op, ncols = 2)\n",
    "    img_grid = make_grid(samples)\n",
    "    g_writer.add_image('Image/pc_sampler', img_grid, global_step=epoch)\n",
    "\n",
    "\n",
    "    samples = Euler_Maruyama_sampler(score_model,\n",
    "                                    marginal_prob_std_fn,\n",
    "                                    diffusion_coeff_fn,\n",
    "                                    sample_batch_size,\n",
    "                                    img_shape=img_shape,\n",
    "                                    device=device,\n",
    "                                    labels=test_label)\n",
    "\n",
    "    img_op = os.path.join(g_video_path, f\"Euler_Maruyama_sampler_{epoch:03d}.jpg\")\n",
    "    # samples = (samples.to(\"cpu\") + 1) * 0.5\n",
    "    samples.clamp(0, 1.0)\n",
    "    ts.save(samples, img_op, ncols = 2)\n",
    "    img_grid = make_grid(samples)\n",
    "    g_writer.add_image('Image/Euler_Maruyama_sampler', img_grid, global_step=epoch)\n",
    "\n",
    "  if avg_loss < best_avg_loss:\n",
    "    best_cnt += 1\n",
    "    if best_cnt % 100 == 0:\n",
    "      best_cnt = 0\n",
    "      print(f\"Best Loss : {avg_loss:.5f}\")\n",
    "\n",
    "    best_avg_loss = avg_loss\n",
    "    model_path = os.path.join(g_model_path, 'ckpt_best.pth')\n",
    "    torch.save(score_model.state_dict(), model_path)\n",
    "\n",
    "  # Print the averaged training loss so far.\n",
    "  tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items))\n",
    "  # Update the checkpoint after each epoch of training.\n",
    "  model_path = os.path.join(g_model_path, 'ckpt_last.pth')\n",
    "  torch.save(score_model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_drill_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
